{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py as pm\n",
    "import numpy as np\n",
    "import psutil as pu\n",
    "\n",
    "from  sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_file_path = 'db/BPI_Challenge_2012.XE-training.csv'\n",
    "testing_file_path = 'db/BPI_Challenge_2012.XE-test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load CSV with pandas and pm4py\n",
    "\n",
    "pm4py gives two extra columns: @@index and @@case_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_event_log(path):\n",
    "    event_log = pd.read_csv(path, sep=',')\n",
    "    event_log = pm.format_dataframe(\n",
    "        event_log, \n",
    "        case_id='case concept:name', \n",
    "        activity_key='event concept:name', \n",
    "        timestamp_key='event time:timestamp'\n",
    "    )\n",
    "    return event_log\n",
    "#event_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that finds the length of the longest trace in a list of traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_trace(traces):\n",
    "    max = 0\n",
    "    for trace in traces:\n",
    "        if trace.shape[0] > max:\n",
    "            max = trace.shape[0]\n",
    "    return max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that adds the Ground truth collumns for event and time of the event\n",
    "- Every value in the ground truth collumns is the actual next event or time of the next evet in the data set\n",
    "- Used for naive simulator\n",
    "- Used for verification purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume sorted by caseID and time\n",
    "def caseHasNextEvent(df, index):\n",
    "    if index >= len(df) - 1:\n",
    "        return False\n",
    "    if df.loc[index, 'case concept:name'] == df.loc[index+1, 'case concept:name']:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def writeGroundtruth(df):\n",
    "    df = df.sort_values(by=['case concept:name','event time:timestamp'])\n",
    "    #add new columns containing the name of the next event in the case and the time when it happens\n",
    "    df = df.assign(ground_truth_activity='')\n",
    "    df = df.assign(ground_truth_time='')\n",
    "\n",
    "    for ind in df.index:\n",
    "        if caseHasNextEvent(df, ind):\n",
    "            df.at[ind,'ground_truth_activity'] = df.loc[ind+1,'event concept:name']\n",
    "            df.at[ind,'ground_truth_time'] = df.loc[ind+1, 'event time:timestamp']\n",
    "        else:\n",
    "            df.at[ind,'ground_truth_activity'] = None\n",
    "            df.at[ind,'ground_truth_time'] = None\n",
    "    return df\n",
    "\n",
    "#df_event = writeGroundtruth(event_log)\n",
    "#df_event.to_csv('check_writeGroundtruth_out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper method for naive estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTimeDifference(df):\n",
    "    # df['time_until_next_event'] = 0  # initialize new column with zeros\n",
    "    df = df.assign(time_until_next_event=0) # initialize new column\n",
    "\n",
    "    # iterate over each row of the dataframe\n",
    "    for i, row in df.iterrows():        \n",
    "        # check if there is a next row with the same case\n",
    "        if caseHasNextEvent(df, i):\n",
    "            nextTime = df.loc[i+1, 'event time:timestamp']\n",
    "            currentTime = row['event time:timestamp']\n",
    "            timeDiff = nextTime - currentTime\n",
    "            df.at[i, 'time_until_next_event'] = timeDiff.total_seconds()\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that splits the data set into separate traces\n",
    "- Parameter $traces$ is a list containing all the individual traces\n",
    "- Each trace in traces is a list containing all the events in the trace in the order that they happen\n",
    "- Helper method for prefix extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_traces(event_log):\n",
    "    traces = []\n",
    "    last_location = 0\n",
    "    for j in range (0, event_log.shape[0] - 1):\n",
    "        if not event_log[\"case concept:name\"][j] == event_log[\"case concept:name\"][j + 1]:\n",
    "            traces.append(event_log.loc[last_location : j].reset_index())\n",
    "            last_location = j + 1\n",
    "    traces.append(event_log.loc[last_location : event_log.shape[0] - 1].reset_index())\n",
    "    return traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that deletes traces from a list that contain events past a specified time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_overlaping_traces(traces, end_time):\n",
    "    del_tr = []\n",
    "    for j in range(len(traces)):\n",
    "        for k in traces[j].index:\n",
    "            trace_ts = traces[j][\"event time:timestamp\"][k]\n",
    "        if trace_ts > end_time:\n",
    "            del_tr.append(j)\n",
    "\n",
    "    i = 0\n",
    "    for j in range(len(del_tr)):\n",
    "        del traces[del_tr[j] - i]\n",
    "        i = i + 1\n",
    "    return traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prefix extraction\n",
    "- extract event lists of odd length like 1, 3, 5, 7, 9, 11, 13, 15 from the traces for prediction\n",
    "- and the ground truth\n",
    "- store them in a list of prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_extraction(traces, prefix_lengths):\n",
    "    prefixes = []\n",
    "    for trace in traces:\n",
    "        for length in prefix_lengths:\n",
    "            if trace.shape[0] > length:\n",
    "                prefixes.append(trace.loc[:length - 1])\n",
    "    return prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregation encoding\n",
    "- endoce traces into numerical data for prediction\n",
    "- adds the ground truth at the end of the encoded prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(event_log):\n",
    "    events = []\n",
    "    events = event_log['event concept:name'].unique()\n",
    "\n",
    "    events_dict = {'ground_truth' : 'truth'}\n",
    "    for event in events:\n",
    "        events_dict[event] = 0\n",
    "    return events_dict\n",
    "\n",
    "def aggregation_encoding(prefixes, event_log):\n",
    "    event_dict = create_dict(event_log)\n",
    "    aggregation_encoding = pd.DataFrame(event_dict, index=[0])\n",
    "    aggregation_encoding = aggregation_encoding.drop(0)\n",
    "    #new_encoding = ['truth', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    index = 0\n",
    "    for prefix in prefixes:\n",
    "        current_dict = create_dict(event_log)\n",
    "        current_dict['ground_truth'] = prefix['ground_truth_activity'][len(prefix.index) - 1]\n",
    "        for event in prefix[\"event concept:name\"]:\n",
    "            current_dict[event] = current_dict[event] + 1\n",
    "        aggregation_encoding.loc[index] = current_dict.values()\n",
    "        index += 1\n",
    "    return aggregation_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aggregation_encoding(path, type):\n",
    "    event_log = format_event_log(path)\n",
    "    traces = split_into_traces(event_log)\n",
    "    prefix_lengths = []\n",
    "    if type == \"train\":\n",
    "        traces = delete_overlaping_traces(traces, pd.to_datetime(\"02-01-2012 15:28:39.244\",format=\"%d-%m-%Y %H:%M:%S.%f\"))\n",
    "        prefix_lengths = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
    "    if type == \"test\":\n",
    "        prefix_lengths = [x for x in range(0, find_longest_trace(traces) + 1)]\n",
    "    prefixes = prefix_extraction(traces, prefix_lengths)\n",
    "    aggregation = aggregation_encoding(prefixes, event_log)\n",
    "    if type == \"train\":\n",
    "        aggregation_encoding.to_csv(\"aggregation_encoding_train.csv\")\n",
    "    if type == \"test\":\n",
    "        aggregation_encoding.to_csv(\"aggregation_encoding_test.csv\")\n",
    "    return aggregation\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_X_Y(df):\n",
    "    dependent_Variable = 'ground_truth'\n",
    "    independent_Variable = df.columns.tolist()\n",
    "    independent_Variable.remove(dependent_Variable)\n",
    "    independent_Variable.remove('Unnamed: 0')\n",
    "\n",
    "    list_of_activities = independent_Variable.copy()\n",
    "    dict_activity_to_int = {a: list_of_activities.index(a) for a in list_of_activities}\n",
    "    \n",
    "    X = df[independent_Variable]\n",
    "    Y = df[dependent_Variable].replace(dict_activity_to_int)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def get_Regression_model_scaler(df_training_encoded):\n",
    "    X, Y = process_X_Y(df_training_encoded)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    # X_test = scaler.transform(X_test) #TODO\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, Y)\n",
    "    \n",
    "    intercept = model.intercept_\n",
    "\n",
    "    return model, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive predictor base on mode and mean\n",
    "1. for each row find next activity of the case and its timestamp\n",
    "2. compute the time it take for the next event to be log in the db\n",
    "3. for each activity find the most common next activity (mode)\n",
    "4. for each activity find the average time between next activity\n",
    "5. Have 3. and 4. in a DataFrame\n",
    "6. base on the current activity write the prediction of the next activity and time it will take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_estimators():\n",
    "    df_train = format_event_log(training_file_path)\n",
    "    df_train = writeGroundtruth(df_train)\n",
    "    df_train = computeTimeDifference(df_train)\n",
    "\n",
    "    df_test = format_event_log(testing_file_path)\n",
    "    df_test = writeGroundtruth(df_test)\n",
    "\n",
    "\n",
    "    df_naive_predictor_dict = df_train.groupby(['event concept:name']).agg(\n",
    "        naive_prediction_activity = ('ground_truth_activity', pd.Series.mode),\n",
    "        naive_prediction_time = ('time_until_next_event', 'mean')\n",
    "    )\n",
    "\n",
    "    df_test = df_test.assign(naive_prediction_activity='')\n",
    "    df_test = df_test.assign(naive_prediction_time=0)\n",
    "    for i, r in df_test.iterrows():\n",
    "        this_event = r['event concept:name']\n",
    "        next_event = df_naive_predictor_dict.loc[this_event,'naive_prediction_activity']\n",
    "        next_event_time = df_naive_predictor_dict.loc[this_event,'naive_prediction_time']\n",
    "        df_test.at[i,'naive_prediction_activity'] = next_event\n",
    "        df_test.at[i,'naive_prediction_time'] = next_event_time\n",
    "    df_train.to_csv('db/Ground_Turth.csv')\n",
    "    df_test.to_csv('db/Navie_Estimator.csv')\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 2 Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivalue Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_estimator():\n",
    "    df_encoded_train = pd.read_csv('aggregation_encoding_train.csv')\n",
    "    df_encoded_test = pd.read_csv('db/aggregation_encoding_test.csv')\n",
    "    \n",
    "    model, scaler = get_Regression_model_scaler(df_encoded_train)\n",
    "    X_test, Y_test = process_X_Y(df_encoded_test)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "\n",
    "\n",
    "    predict = model.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sprint2_predict_event():\n",
    "    train_file_path = 'db/naive_predictor_result.csv'\n",
    "    test_file_path = 'db/BPI_Challenge_2012.XE-test.csv'\n",
    "    train_aggregation = get_aggregation_encoding(train_file_path, \"train\")\n",
    "    test_aggregation = get_aggregation_encoding(test_file_path, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_model_activity():\n",
    "    predictor_path = \"naive_predictor_result.csv\"\n",
    "    df_error_model = pd.read_csv(predictor_path)\n",
    "    df_error_model['error_activity'] = df_error_model['ground_truth_activity'] == df_error_model['naive_prediction_activity']\n",
    "    df_error_model['error_time'] = df_error_model['naive_prediction_time'] - df_error_model['time_until_next_event']\n",
    "    correct_predictions = df_error_model['error_activity'].value_counts()\n",
    "    percentage = correct_predictions[True] / len(df_error_model['error_activity']) * 100\n",
    "    mean_absolute_error = df_error_model['error_time'].mean()\n",
    "    print(f'Percentage of True values: {percentage:.1f}%')\n",
    "    print(mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory and CPU Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_memory_cpu() : \n",
    "    print('The CPU usage is: ', pu.cpu_percent(4))\n",
    "    print('RAM memory % used:', pu.virtual_memory()[2])\n",
    "    print('RAM Used (GB):', pu.virtual_memory()[3]/1000000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main class\n",
    "1. All functions that are needed all called in this cell.\n",
    "2. No other cell runs code other than the main cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linyu\\AppData\\Local\\Temp\\ipykernel_10004\\945299891.py:3: DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0. the format_dataframe function does not need application anymore.\n",
      "  event_log = pm.format_dataframe(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "naive_estimators()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b70c613820eb82f44088773ffc2add453462ad8308f78b60a549bce82e221db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
